# Selective FixMatch Training Collapse: Diagnosis and Fix

## ðŸ“Š Problem Summary

**Observed Symptoms (Epoch 6):**
- Total Loss: 0.0001 (near zero)
- Supervised Loss: 0.0000 (near zero)
- Consistency Loss: 0.0000 (near zero)
- **Mask Rate: 100%** (all pseudo-labels accepted!)
- **Val AUC: 0.4445** (worse than random, model collapsed)
- Val Precision: 0.4143, Recall: 1.0000 (predicting everything as positive)

## ðŸ” Root Cause Analysis

### Critical Bug #1: Incorrect Confidence Threshold Logic âš ï¸

**Original Code (WRONG):**
```python
# Line 116-121 in losses_selectivefixmatch.py
confidence = torch.abs(weak_probs - 0.5) * 2  # Scale to [0, 1]
high_conf_mask = confidence >= self.confidence_threshold
```

**Problem:**
With `confidence_threshold = 0.8`:
- If model predicts p=0.99 for all samples â†’ `confidence = |0.99 - 0.5| * 2 = 0.98` â†’ ALL pass threshold!
- Result: 100% mask rate when model collapses to predicting everything as positive
- The model gets rewarded for being confident, even if wrong

**Why This Caused Collapse:**
1. Model starts predicting slightly more positives (random)
2. These predictions have "high confidence" by the buggy metric
3. Consistency loss reinforces these predictions
4. Positive feedback loop â†’ model predicts everything as positive
5. Gradient flow stops (loss near zero)

### Critical Bug #2: Misunderstanding FixMatch Threshold

**FixMatch Principle:** Only use pseudo-labels when prediction is **very close to 0 or 1**, not just "far from 0.5".

**Correct Implementation:**
```python
# FIXED: Use predictions very close to 0 or 1
# threshold=0.95 means use if p >= 0.95 OR p <= 0.05
high_conf_mask = (weak_probs >= self.confidence_threshold) | \
                (weak_probs <= (1.0 - self.confidence_threshold))
```

Now with `confidence_threshold = 0.95`:
- Only use samples where model predicts p â‰¥ 0.95 (very positive) or p â‰¤ 0.05 (very negative)
- Typical mask rate: 20-40% (healthy)
- Model learns from only high-quality pseudo-labels

## ðŸ› ï¸ Fixes Applied

### 1. **Fixed Confidence Threshold Logic**
**File:** `models/losses_selectivefixmatch.py` (lines 116-120)

```python
# OLD (BROKEN):
confidence = torch.abs(weak_probs - 0.5) * 2
high_conf_mask = confidence >= self.confidence_threshold

# NEW (FIXED):
high_conf_mask = (weak_probs >= self.confidence_threshold) | \
                (weak_probs <= (1.0 - self.confidence_threshold))
```

### 2. **Added Debug Logging**
Added tracking of min/max/mean probabilities:
```python
metrics['weak_prob_min'] = weak_probs.min().item()
metrics['weak_prob_max'] = weak_probs.max().item()
metrics['weak_prob_mean'] = weak_probs.mean().item()
```

This helps detect if model is collapsing (all probs â†’ 1 or 0).

### 3. **Adjusted Hyperparameters for Stability**

**New Config:** `configs/selective_fixmatch_v2.yaml`

| Parameter | Old Value | New Value | Reason |
|-----------|-----------|-----------|---------|
| `confidence_threshold` | 0.80 | **0.95** | More selective pseudo-labeling |
| `lr` | 0.001 | **0.0001** | Slower, more stable learning |
| `grad_clip` | - | **1.0** | Prevent gradient explosion |
| `weight_decay` | 0.0001 | **0.0001** | Keep same (already good) |

### 4. **Enhanced Progress Bar**
Now shows mean probability during training:
```
loss=0.4312 | L_sup=0.3145 | L_cons=0.1167 | mask=35.2% | p_mean=0.623
```

## ðŸ“ˆ Expected Behavior After Fix

### Healthy Training Metrics:
```
Epoch 1:  L_sup=0.65 | L_cons=0.00 | Mask=0%   | AUC=0.72 | p_mean=0.52
Epoch 5:  L_sup=0.42 | L_cons=0.15 | Mask=25%  | AUC=0.81 | p_mean=0.58
Epoch 10: L_sup=0.31 | L_cons=0.12 | Mask=35%  | AUC=0.87 | p_mean=0.61
Epoch 20: L_sup=0.25 | L_cons=0.08 | Mask=40%  | AUC=0.91 | p_mean=0.63
Epoch 30: L_sup=0.21 | L_cons=0.06 | Mask=42%  | AUC=0.93 | p_mean=0.64
```

### Key Indicators:
- **Mask Rate**: 20-60% (NOT 0% or 100%)
- **Loss Values**: Gradually decreasing (NOT near zero)
- **Val AUC**: > 0.7 after a few epochs
- **p_mean**: Slowly increasing from ~0.5 (NOT jumping to 1.0)

## ðŸš€ How to Use Fixed Version

### Training Command:
```bash
python train_selective_fixmatch.py \
    --config configs/selective_fixmatch_v2.yaml \
    --exp-name selective_fixmatch_fixed \
    --device cuda:0
```

### Multi-GPU:
```bash
python train_selective_fixmatch.py \
    --config configs/selective_fixmatch_v2.yaml \
    --exp-name selective_fixmatch_fixed \
    --device cuda \
    --multi-gpu
```

### Monitor for Issues:
```bash
tail -f train_selective_fixmatch_fixed.log | grep -E "Mask|AUC|p_mean"
```

**Red Flags:**
- Mask rate = 0% â†’ threshold too high, lower to 0.90
- Mask rate = 100% â†’ bug, check if using fixed version
- p_mean > 0.95 early â†’ model collapsing, restart with lower LR

## ðŸ“ Testing Results

**Loss Function Unit Test:**
```
Epoch 0:  Mask rate: 16.67% | L_cons=1.46 âœ“
Epoch 10: Mask rate: 16.67% | L_cons=1.46 âœ“
```
With random predictions, ~17% pass threshold=0.95 (expected for random data).

## ðŸ”‘ Key Takeaways

### What Caused the Collapse:
1. **Buggy confidence metric** allowed model to be rewarded for being confidently wrong
2. **Positive feedback loop** reinforced predictions (predict positive â†’ confident â†’ reinforce â†’ predict more positive)
3. **100% mask rate** meant consistency loss was applied to ALL samples (no filtering)
4. **Gradients vanished** when model predicted same value for everything

### How the Fix Works:
1. **Correct threshold** only uses predictions very close to 0 or 1
2. **Selective pseudo-labeling** filters out uncertain predictions
3. **Lower LR** prevents rapid collapse
4. **Gradient clipping** prevents explosion

### Prevention:
- Always validate confidence threshold logic with unit tests
- Monitor mask rate during training (should be 20-60%)
- Add debug logging for probability distributions
- Use lower learning rates for semi-supervised learning

---

## ðŸ“¦ Files Modified

1. âœ… `models/losses_selectivefixmatch.py` - Fixed confidence threshold logic
2. âœ… `configs/selective_fixmatch_v2.yaml` - Stable hyperparameters
3. âœ… `train_selective_fixmatch.py` - Enhanced logging

## ðŸŽ¯ Success Criteria

Training is successful if:
- [ ] Mask rate between 20-60% throughout training
- [ ] Val AUC > 0.70 by epoch 10
- [ ] Val AUC > 0.85 by epoch 30
- [ ] Loss values gradually decrease (not stuck at 0)
- [ ] p_mean slowly increases (not jumping to 1.0)

---

**Status:** âœ… Fixed and Ready for Training
**Version:** v2 (Stable)
**Date:** 2025-10-05

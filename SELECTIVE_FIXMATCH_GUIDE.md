# Selective FixMatch + PU Learning Guide

Updated implementation with safer consistency regularization and robust inference.

## Key Improvements

### 1. Selective FixMatch (Negative-only Consistency)

**Problem Solved:** Standard FixMatch applies consistency loss uniformly, which can harm positive patches where strong augmentations might crop or distort particles.

**Solution:** 
- Apply consistency loss ONLY to unlabeled/negative patches
- Positive and False Positive patches use supervised learning only
- Preserves particle integrity while still benefiting from semi-supervised learning

```python
# In training loop:
if sample_type == -1:  # Unlabeled
    apply_consistency_loss(weak, strong)  # FixMatch
else:  # Positive or False Positive
    apply_supervised_loss(weak, label)  # Standard BCE
```

### 2. Sliding Window Inference

**Features:**
- Dense sliding window with configurable stride
- Overlapping predictions averaged for smoothness
- Handles full micrographs efficiently
- Batch processing for speed

### 3. Probability Map + NMS

**Pipeline:**
1. Generate probability map from sliding window
2. Find local maxima above threshold
3. Apply Non-Maximum Suppression
4. Output final particle coordinates

## Usage

### Training with Selective FixMatch

```bash
# Train with selective consistency regularization
python train_selective_fixmatch.py \
  --config configs/selective_fixmatch.yaml \
  --exp-name selective_run \
  --data-path data/processed \
  --num-workers 4
```

### Inference on Micrographs

```bash
# Run sliding window inference on micrographs
python inference_sliding_window.py \
  --checkpoint experiments/selective_run/best_model.pt \
  --input /path/to/micrographs/ \
  --output-dir results/ \
  --stride 32 \
  --prob-threshold 0.5 \
  --min-distance 20 \
  --visualize
```

### Output Formats

```bash
# CSV format (default)
python inference_sliding_window.py ... --output-format csv

# STAR format (for RELION)
python inference_sliding_window.py ... --output-format star

# BOX format (for EMAN)
python inference_sliding_window.py ... --output-format box
```

## Configuration Parameters

### Training Parameters

```yaml
loss:
  # Selective FixMatch settings
  consistency_threshold: 0.8  # Confidence threshold for pseudo-labels
  lambda_consistency: 0.5     # Weight for consistency loss
  apply_to_positives: false   # Don't apply to positive patches
  apply_to_false_positives: false  # Don't apply to FP patches
  
  # PU Learning settings
  prior: 0.197  # Estimated from data
  beta: -0.01   # nnPU margin
```

### Inference Parameters

```yaml
inference:
  stride: 32           # Sliding window stride (smaller = more overlap)
  prob_threshold: 0.5  # Minimum probability for detection
  min_distance: 20     # Minimum distance between particles
  peak_threshold: 0.3  # Threshold for local maxima
  nms_threshold: 0.5   # IoU threshold for NMS
```

## Expected Performance

### Training Metrics
- **Mask Rate**: Should be 20-40% (percentage of unlabeled data used)
- **Val AUC**: Should gradually increase from 0.5 to 0.65+
- **Consistency Loss**: Should decrease but not dominate

### Inference Performance
- **Speed**: ~5-10 seconds per 2048x2048 micrograph on GPU
- **Memory**: ~2-4GB GPU memory depending on batch size
- **Detection Rate**: 70-85% recall at 80% precision (typical)

## Monitoring Training

### Check Selective FixMatch is Working

```python
# Training output should show:
Batch 10/280 | Loss: 0.8234 | PU: 0.5123 | Cons: 0.3111 | 
Mask Rate: 32.5% | Unlabeled Used: 26/80
```

- **Mask Rate**: Percentage of unlabeled samples passing threshold
- **Unlabeled Used**: Actual count of samples used for consistency

### Debugging Low Performance

1. **Check mask rate**: If < 10%, threshold is too high
2. **Monitor gradient norms**: Should be 0.01-1.0 range
3. **Check prediction distribution**: Should not collapse to 0 or 1
4. **Verify batch composition**: Should match P:U:FP ratio

## Advanced Usage

### Custom Augmentations

```python
# Modify datasets/transforms_cryoem.py
weak_transform = Compose([
    RandomFlip(p=0.5),
    RandomSmallRotation(degrees=15),
    # Add custom transforms here
])
```

### Multi-GPU Training

```bash
# Use PyTorch DDP (not yet implemented)
torchrun --nproc_per_node=2 train_selective_fixmatch.py ...
```

### Ensemble Inference

```python
# Average predictions from multiple models
prob_maps = []
for checkpoint in checkpoints:
    model = load_model(checkpoint)
    prob_map = inference.infer_micrograph(image)
    prob_maps.append(prob_map)

final_map = np.mean(prob_maps, axis=0)
```

## Troubleshooting

### Issue: Val AUC stuck at 0.5
- Reduce learning rate to 1e-5
- Increase warmup epochs
- Check data quality
- Try supervised-only baseline first

### Issue: Too many false positives
- Increase prob_threshold (e.g., 0.6)
- Increase min_distance for NMS
- Add post-processing filters

### Issue: Missing particles
- Decrease stride for denser sampling
- Lower prob_threshold (e.g., 0.4)
- Check if particles are at image edges

### Issue: Out of memory during inference
- Reduce batch_size for inference
- Process smaller image tiles
- Use CPU for very large micrographs

## Comparison with Standard FixMatch

| Feature | Standard FixMatch | Selective FixMatch |
|---------|------------------|-------------------|
| Consistency on Positives | Yes âŒ | No âœ… |
| Risk of particle distortion | High | Low |
| Unlabeled utilization | 100% | 100% |
| Training stability | Lower | Higher |
| Final performance | Variable | More consistent |

## Citation

If you use this implementation, please cite:
- FixMatch: Sohn et al., NeurIPS 2020
- nnPU Learning: Kiryo et al., NeurIPS 2017
- Your paper when published ðŸ˜Š

## Files Overview

- `train_selective_fixmatch.py`: Main training script with selective consistency
- `inference_sliding_window.py`: Full micrograph inference with NMS
- `configs/selective_fixmatch.yaml`: Recommended configuration
- `models/fixmatch_pu.py`: Model architecture (unchanged)
- `models/losses_fixed.py`: PU loss implementation (unchanged)

## Next Steps

1. **Start Training**: Use the provided config to begin training
2. **Monitor Progress**: Check mask rate and Val AUC
3. **Run Inference**: Test on full micrographs
4. **Fine-tune**: Adjust thresholds based on results
5. **Production**: Deploy for large-scale particle picking

Good luck with your particle picking! ðŸ”¬âœ¨